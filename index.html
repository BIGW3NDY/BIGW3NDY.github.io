<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="true" />














  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="魔力弹">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="魔力弹">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="魔力弹">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>魔力弹</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">魔力弹</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">d=====(￣▽￣*)b</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/16/cuda分布式计算之优化实例（矩阵相乘）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="DingHH">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="魔力弹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/16/cuda分布式计算之优化实例（矩阵相乘）/" itemprop="url">cuda分布式计算之优化实例（矩阵相乘）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-16T23:14:22+08:00">
                2018-11-16
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/11/16/cuda分布式计算之优化实例（矩阵相乘）/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/11/16/cuda分布式计算之优化实例（矩阵相乘）/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>用矩阵相乘为例，用gpu进行优化，一步步一共写出了三个版本，分别是使用全局内存，纹理内存和共享内存。为了编写方便，代码中默认把两个矩阵写成了一个大小。</p>
<h2 id="全局内存"><a href="#全局内存" class="headerlink" title="全局内存"></a>全局内存</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include&lt;stdio.h&gt;</span></span><br><span class="line"><span class="comment">#include&lt;cuda_runtime.h&gt;</span></span><br><span class="line"><span class="comment">#include&lt;time.h&gt;</span></span><br><span class="line">const int size = 512;</span><br><span class="line"></span><br><span class="line">__global__ void matMultCUDA(<span class="built_in">float</span>* a, <span class="built_in">float</span>* b, <span class="built_in">float</span>* c,int ha, int wa, int wb)&#123;//wa = hb</span><br><span class="line">	int tid = threadIdx.x;</span><br><span class="line">	int bid = blockIdx.x;</span><br><span class="line">	int offset = bid*blockDim.x+tid;</span><br><span class="line">	</span><br><span class="line">	int row = offset/wb;</span><br><span class="line">	int column = offset%wb;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">if</span>(row&lt;ha)&#123;</span><br><span class="line">		<span class="built_in">float</span> t = 0;</span><br><span class="line">		<span class="keyword">for</span>(int i=0;i&lt;wa;i++)</span><br><span class="line">			t += a[row*wa+i]*b[i*wb+column];</span><br><span class="line">		c[row*wb+column] = t;	</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(void)&#123;</span><br><span class="line">	clock_t start,finish;</span><br><span class="line">	<span class="built_in">float</span>* a = new <span class="built_in">float</span>[size*size];</span><br><span class="line">	<span class="built_in">float</span>* b = new <span class="built_in">float</span>[size*size];</span><br><span class="line">	<span class="built_in">float</span>* c = new <span class="built_in">float</span>[size*size];</span><br><span class="line">	</span><br><span class="line">	<span class="built_in">float</span> *dev_a, *dev_b, *dev_c;</span><br><span class="line">	cudaMalloc((void**)&amp;dev_a,size*size*sizeof(<span class="built_in">float</span>));</span><br><span class="line">	cudaMalloc((void**)&amp;dev_b,size*size*sizeof(<span class="built_in">float</span>));</span><br><span class="line">	cudaMalloc((void**)&amp;dev_c,size*size*sizeof(<span class="built_in">float</span>));</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span>(int i=0;i&lt;size*size;i++)&#123;</span><br><span class="line">		a[i] = i;</span><br><span class="line">		b[i] = 2*i;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	cudaMemcpy(dev_a,a,size*size*sizeof(<span class="built_in">float</span>),cudaMemcpyHostToDevice);</span><br><span class="line">	cudaMemcpy(dev_b,b,size*size*sizeof(<span class="built_in">float</span>),cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">	start = clock();</span><br><span class="line">	matMultCUDA&lt;&lt;&lt;size,size&gt;&gt;&gt;(dev_a,dev_b,dev_c,size,size,size);	</span><br><span class="line">	finish = clock();</span><br><span class="line">	</span><br><span class="line">	cudaMemcpy(c,dev_c,size*size*sizeof(<span class="built_in">float</span>),cudaMemcpyDeviceToHost);</span><br><span class="line">	//<span class="keyword">for</span>(int i=0;i&lt;size;i++)&#123;</span><br><span class="line">	//	<span class="keyword">for</span>(int j=0;j&lt;size;j++)&#123;</span><br><span class="line">	//		<span class="built_in">printf</span>(<span class="string">"%.0f "</span>,c[i*size+j]);</span><br><span class="line">	//	&#125;</span><br><span class="line">	//	<span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">	//&#125;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"%f\n"</span>,(<span class="built_in">float</span>)(finish-start)/CLOCKS_PER_SEC);</span><br><span class="line">	cudaFree(dev_a);</span><br><span class="line">	cudaFree(dev_b);</span><br><span class="line">	cudaFree(dev_c);</span><br><span class="line"></span><br><span class="line">	free(a);</span><br><span class="line">	free(b);</span><br><span class="line">	free(c);</span><br><span class="line">	<span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="纹理内存"><a href="#纹理内存" class="headerlink" title="纹理内存"></a>纹理内存</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include&lt;stdio.h&gt;</span></span><br><span class="line"><span class="comment">#include&lt;cuda_runtime.h&gt;</span></span><br><span class="line"><span class="comment">#include&lt;time.h&gt;</span></span><br><span class="line">const int size = 512;</span><br><span class="line"></span><br><span class="line">texture&lt;<span class="built_in">float</span>&gt; texA;</span><br><span class="line">texture&lt;<span class="built_in">float</span>&gt; texB;</span><br><span class="line"></span><br><span class="line">__global__ void matMultTexture(<span class="built_in">float</span>* c, int ha, int wa, int wb)&#123;</span><br><span class="line">	int tid = threadIdx.x;</span><br><span class="line">	int bid = blockIdx.x;</span><br><span class="line">	int offset = bid*blockDim.x+tid;</span><br><span class="line">	</span><br><span class="line">	int row = offset/wb;</span><br><span class="line">	int column = offset%wb;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">if</span>(row&lt;ha)&#123;</span><br><span class="line">		<span class="built_in">float</span> t = 0;</span><br><span class="line">		<span class="keyword">for</span>(int i=0;i&lt;wa;i++)&#123;</span><br><span class="line">			<span class="built_in">float</span> a = tex1Dfetch(texA,row*wa+i);</span><br><span class="line">			<span class="built_in">float</span> b = tex1Dfetch(texB,i*wb+column);</span><br><span class="line">			t += a*b;</span><br><span class="line">		&#125;</span><br><span class="line">		c[row*wb+column] = t;	</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(void)&#123;</span><br><span class="line">	clock_t start,finish;</span><br><span class="line">	<span class="built_in">float</span>* a = new <span class="built_in">float</span>[size*size];</span><br><span class="line">	<span class="built_in">float</span>* b = new <span class="built_in">float</span>[size*size];</span><br><span class="line">	<span class="built_in">float</span>* c = new <span class="built_in">float</span>[size*size];</span><br><span class="line"></span><br><span class="line">	<span class="built_in">float</span> *dev_a, *dev_b, *dev_c;</span><br><span class="line">	cudaMalloc((void**)&amp;dev_a,size*size*sizeof(<span class="built_in">float</span>));</span><br><span class="line">	cudaMalloc((void**)&amp;dev_b,size*size*sizeof(<span class="built_in">float</span>));</span><br><span class="line">	cudaMalloc((void**)&amp;dev_c,size*size*sizeof(<span class="built_in">float</span>));</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span>(int i=0;i&lt;size*size;i++)&#123;</span><br><span class="line">		a[i] = i;</span><br><span class="line">		b[i] = 2*i;</span><br><span class="line">	&#125;</span><br><span class="line">	cudaMemcpy(dev_a,a,size*size*sizeof(<span class="built_in">float</span>),cudaMemcpyHostToDevice);</span><br><span class="line">	cudaMemcpy(dev_b,b,size*size*sizeof(<span class="built_in">float</span>),cudaMemcpyHostToDevice);</span><br><span class="line">	</span><br><span class="line">	cudaBindTexture(NULL,texA,dev_a);</span><br><span class="line">	cudaBindTexture(NULL,texB,dev_b);</span><br><span class="line"></span><br><span class="line">	start = clock();</span><br><span class="line">	matMultTexture&lt;&lt;&lt;size,size&gt;&gt;&gt;(dev_c,size,size,size);</span><br><span class="line">	finish = clock();</span><br><span class="line">	cudaMemcpy(c,dev_c,size*size*sizeof(<span class="built_in">float</span>),cudaMemcpyDeviceToHost);</span><br><span class="line">	//<span class="keyword">for</span>(int i=0;i&lt;size;i++)&#123;</span><br><span class="line">	//	<span class="keyword">for</span>(int j=0;j&lt;size;j++)&#123;</span><br><span class="line">	//		<span class="built_in">printf</span>(<span class="string">"%.0f "</span>,c[i*size+j]);</span><br><span class="line">	//	&#125;</span><br><span class="line">	//	<span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">	//&#125;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"%f\n"</span>,(<span class="built_in">float</span>)(finish-start)/CLOCKS_PER_SEC);</span><br><span class="line">	cudaFree(dev_a);</span><br><span class="line">	cudaFree(dev_b);</span><br><span class="line">	cudaFree(dev_c);</span><br><span class="line">	cudaUnbindTexture(texA);</span><br><span class="line">	cudaUnbindTexture(texB);</span><br><span class="line">	free(a);</span><br><span class="line">	free(b);</span><br><span class="line">	free(c);</span><br><span class="line">	<span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">//对于核函数做出了改动，cpu部分代码与使用全局内存时相同</span><br><span class="line">__global__ void matMultCUDA(<span class="built_in">float</span>* a, <span class="built_in">float</span>* b, <span class="built_in">float</span>* c,int ha, int wa, int wb)&#123;//wa = hb</span><br><span class="line">	__shared__ <span class="built_in">float</span> data[size];	</span><br><span class="line">	int tid = threadIdx.x;</span><br><span class="line">	int bid = blockIdx.x;</span><br><span class="line">	int offset = bid*blockDim.x+tid;</span><br><span class="line">	</span><br><span class="line">	data[tid] = a[offset];</span><br><span class="line">	</span><br><span class="line">	__syncthreads();</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">for</span>(int i=0;i&lt;wb;i++)&#123;</span><br><span class="line">		<span class="built_in">float</span> t = 0;</span><br><span class="line">		<span class="keyword">for</span>(int j=0;j&lt;ha;j++)&#123;</span><br><span class="line">			t += data[j]*b[j*wb+i];</span><br><span class="line">		&#125;</span><br><span class="line">		c[bid*wb+i] = t;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/16/cuda分布计算之并行规约/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="DingHH">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="魔力弹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/16/cuda分布计算之并行规约/" itemprop="url">cuda分布式计算之并行规约</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-16T23:09:22+08:00">
                2018-11-16
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/11/16/cuda分布计算之并行规约/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/11/16/cuda分布计算之并行规约/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="并行归约"><a href="#并行归约" class="headerlink" title="并行归约"></a>并行归约</h2><p>对一个输入数组执行某种计算，产生一个更小的结果数组。</p>
<p>适用场景：取最小、取最大、求和、平方和、逻辑与/或、向量点积。</p>
<h3 id="例子：计算矢量和"><a href="#例子：计算矢量和" class="headerlink" title="例子：计算矢量和"></a>例子：计算矢量和</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include&lt;stdio.h&gt;</span></span><br><span class="line"><span class="comment">#include&lt;cuda_runtime.h&gt;</span></span><br><span class="line"></span><br><span class="line">const int size = 1024;</span><br><span class="line"></span><br><span class="line">__global__ void parallel_reduction_sum(int* in_vec, int* out_vec, int size)&#123;</span><br><span class="line">	int tid = threadIdx.x;</span><br><span class="line">	int *local_vec = in_vec + blockDim.x * blockIdx.x;</span><br><span class="line">	<span class="keyword">if</span>(tid + blockDim.x*blockIdx.x&gt;=size)</span><br><span class="line">		<span class="built_in">return</span>;	</span><br><span class="line">	int step = 2;</span><br><span class="line">	<span class="keyword">while</span>(step &lt;= blockDim.x)&#123;</span><br><span class="line">		<span class="keyword">if</span>(tid % step == 0)</span><br><span class="line">			local_vec[tid]+=local_vec[tid+step/2];</span><br><span class="line">		__syncthreads();</span><br><span class="line">		step*=2;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span>(tid == 0 ) </span><br><span class="line">		out_vec[blockIdx.x] = local_vec[0];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>()&#123;</span><br><span class="line">	int *in_data,*out_data;</span><br><span class="line">	in_data = new int[size];</span><br><span class="line">	out_data = new int[size];</span><br><span class="line">	</span><br><span class="line">	int sum = 0;</span><br><span class="line">	<span class="keyword">for</span>(int i=0;i&lt;size;i++)&#123;</span><br><span class="line">		in_data[i] = i;</span><br><span class="line">		sum += i;	</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"%d\n"</span>,sum);</span><br><span class="line"></span><br><span class="line">	int *in_vec,*out_vec;</span><br><span class="line">	cudaMalloc((void**)&amp;in_vec,size*sizeof(int));</span><br><span class="line">	cudaMalloc((void**)&amp;out_vec,size*sizeof(int));</span><br><span class="line"></span><br><span class="line">	cudaMemcpy(in_vec,in_data,size*sizeof(int),cudaMemcpyHostToDevice);</span><br><span class="line">	parallel_reduction_sum&lt;&lt;&lt;16,64&gt;&gt;&gt;(in_vec,out_vec,size);</span><br><span class="line">	cudaMemcpy(out_data,out_vec,size*sizeof(int),cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">	sum = 0;</span><br><span class="line">	<span class="keyword">for</span>(int i=0;i&lt;16;i++)</span><br><span class="line">		sum+=out_data[i];</span><br><span class="line"></span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"%d\n"</span>,sum);</span><br><span class="line">	<span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="例子：寻找矩阵最大值并且记录位置"><a href="#例子：寻找矩阵最大值并且记录位置" class="headerlink" title="例子：寻找矩阵最大值并且记录位置"></a>例子：寻找矩阵最大值并且记录位置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include&lt;stdio.h&gt;</span></span><br><span class="line"><span class="comment">#include&lt;cuda_runtime.h&gt;</span></span><br><span class="line"></span><br><span class="line">const int block = 256;</span><br><span class="line">const int thread = 256;</span><br><span class="line"></span><br><span class="line">__global__ void max_spike_local(int* dev_matrix,int* dev_max_local,int size, int *location_x,int *location_y)&#123;</span><br><span class="line">	int tid = threadIdx.x;</span><br><span class="line">	__shared__ int local_matrix[thread];</span><br><span class="line">	__shared__ int location[thread];</span><br><span class="line">	local_matrix[tid] = dev_matrix[tid+blockDim.x*blockIdx.x];</span><br><span class="line">	location[tid] = tid + blockDim.x*blockIdx.x;	</span><br><span class="line">	__syncthreads();</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span>(int i=size/2;i&gt;0;i/=2)&#123;</span><br><span class="line">		<span class="keyword">if</span>(tid&lt;i)&#123;	</span><br><span class="line">			<span class="keyword">if</span>(local_matrix[tid] &lt; local_matrix[tid+i])&#123;</span><br><span class="line">				local_matrix[tid] = local_matrix[tid+i];</span><br><span class="line">				location[tid] = location[tid+i];			</span><br><span class="line">			&#125;					</span><br><span class="line">		&#125;	</span><br><span class="line">		__syncthreads();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span>(tid==0)&#123;</span><br><span class="line">		dev_max_local[blockIdx.x] = local_matrix[0];</span><br><span class="line">		location_x[blockIdx.x] = blockIdx.x;</span><br><span class="line">		location_y[blockIdx.x] = location[tid]-blockIdx.x*thread;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__global__ void max_spike_global(int* dev_max_local, int size,int *location_x, int* location_y)&#123;</span><br><span class="line">	int tid = threadIdx.x;</span><br><span class="line">	__shared__ int max_local[block];</span><br><span class="line">	__shared__ int location_x_share[block];</span><br><span class="line">	__shared__ int location_y_share[block];</span><br><span class="line">	max_local[tid] = dev_max_local[tid];</span><br><span class="line">	location_x_share[tid] = location_x[tid];</span><br><span class="line">	location_y_share[tid] = location_y[tid];</span><br><span class="line">	__syncthreads();</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span>(int i=size/2;i&gt;0;i/=2)&#123;</span><br><span class="line">		<span class="keyword">if</span>(tid&lt;i)&#123;</span><br><span class="line">			<span class="keyword">if</span>(max_local[tid]&lt;max_local[tid+i])&#123;</span><br><span class="line">				max_local[tid] = max_local[tid+i];</span><br><span class="line">				location_x_share[tid] = location_x_share[tid+i];</span><br><span class="line">				location_y_share[tid] = location_y_share[tid+i];		</span><br><span class="line">			&#125;		</span><br><span class="line">		&#125;</span><br><span class="line">		__syncthreads();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span>(tid==0)&#123;</span><br><span class="line">		location_x[0] = location_x_share[0];</span><br><span class="line">		location_y[0] = location_y_share[0];</span><br><span class="line">		dev_max_local[0] = max_local[0];	</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(void)&#123;</span><br><span class="line">	int* matrix = new int[block*thread];</span><br><span class="line">	int* max_local = new int[block];</span><br><span class="line">	int* dev_matrix;</span><br><span class="line">	int* dev_max_local;</span><br><span class="line">	int* location_x;</span><br><span class="line">	int* location_y;</span><br><span class="line"></span><br><span class="line">	int max = 0;	</span><br><span class="line">	int xx=0,yy=0,maxx=0;</span><br><span class="line">	<span class="keyword">for</span>(int i=0;i&lt;block;i++)&#123;</span><br><span class="line">		<span class="keyword">for</span>(int j=0;j&lt;thread;j++)&#123;</span><br><span class="line">			matrix[block*i+j] = rand()%1000000;</span><br><span class="line">			max = matrix[block*i+j]&gt;max?matrix[block*i+j]:max;</span><br><span class="line">			<span class="keyword">if</span>(maxx &lt; matrix[block*i+j])&#123;</span><br><span class="line">				maxx = 	matrix[block*i+j];</span><br><span class="line">				xx=i;</span><br><span class="line">				yy=j;	</span><br><span class="line">			&#125;		</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"%d "</span>,max);</span><br><span class="line">		max = 0;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"%d %d %d"</span>,maxx,xx,yy);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"\n\n"</span>);</span><br><span class="line"></span><br><span class="line">	cudaMalloc((void**)&amp;dev_matrix,block*thread*sizeof(int));</span><br><span class="line">	cudaMalloc((void**)&amp;dev_max_local,block*sizeof(int));</span><br><span class="line">	cudaMalloc((void**)&amp;location_x,block*sizeof(int));</span><br><span class="line">	cudaMalloc((void**)&amp;location_y,block*sizeof(int));</span><br><span class="line">	cudaMemcpy(dev_matrix,matrix,block*thread*sizeof(int),cudaMemcpyHostToDevice);</span><br><span class="line">	max_spike_local&lt;&lt;&lt;block,thread&gt;&gt;&gt;(dev_matrix,dev_max_local,thread,location_x,location_y);</span><br><span class="line">	cudaMemcpy(max_local,dev_max_local,block*sizeof(int),cudaMemcpyDeviceToHost);</span><br><span class="line">	<span class="keyword">for</span>(int i=0;i&lt;block;i++)</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"%d "</span>,max_local[i]);	</span><br><span class="line">	</span><br><span class="line">	max_spike_global&lt;&lt;&lt;1,block&gt;&gt;&gt;(dev_max_local,block,location_x,location_y);</span><br><span class="line">	cudaMemcpy(max_local,dev_max_local,block*sizeof(int),cudaMemcpyDeviceToHost);</span><br><span class="line">	int x,y;</span><br><span class="line">	x = new int[block];</span><br><span class="line">	y = new int[block];</span><br><span class="line">	cudaMemcpy(x,location_x,block*sizeof(int),cudaMemcpyDeviceToHost);</span><br><span class="line">	cudaMemcpy(y,location_y,block*sizeof(int),cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"%d %d %d\n"</span>,max_local[0],x[0],y[0]);	</span><br><span class="line">	cudaFree(dev_matrix);</span><br><span class="line">	cudaFree(dev_max_local);</span><br><span class="line">	cudaFree(location_x);</span><br><span class="line">	cudaFree(location_y);	</span><br><span class="line">	free(matrix);</span><br><span class="line">	free(max_local);</span><br><span class="line">	free(x);</span><br><span class="line">	free(y);	</span><br><span class="line">	<span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/16/cuda分布式计算之内存处理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="DingHH">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="魔力弹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/16/cuda分布式计算之内存处理/" itemprop="url">cuda分布式计算之内存处理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-16T22:35:38+08:00">
                2018-11-16
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/11/16/cuda分布式计算之内存处理/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/11/16/cuda分布式计算之内存处理/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在复习cuda并行计算的时候，做的一些整理，对GPU上的存储器都通过一个小例子使用了一遍。</p>
<h2 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h2><p>同一个线程块共享这块内存。</p>
<p>声明：__share__ float cache[threadPerBlock] (在核函数内声明)</p>
<p>同步：__syncthreads()</p>
<p>确保线程块中的每个线程都执行完__syncthreads()前的语句才会执行下一条语句。</p>
<p>注意：不要将 __syncthreads()置于发散分支中，这样一些线程永远也无法执行 __syncthreads()，导致该线程块中的所有线程保持等待。</p>
<p>例子：向量点积（使用到归约的思想）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include&lt;stdio.h&gt;</span></span><br><span class="line"><span class="comment">#include&lt;cuda_runtime.h&gt;</span></span><br><span class="line"></span><br><span class="line">const int N = 33*1024;</span><br><span class="line">const int threadPerBlock = 256;</span><br><span class="line">const int blockPerGrid = min(32,(N+threadPerBlock-1)/threadPerBlock);</span><br><span class="line"></span><br><span class="line">__global__ void dot(<span class="built_in">float</span> *a, <span class="built_in">float</span> *b, <span class="built_in">float</span> *sum)&#123;</span><br><span class="line">	__shared__ <span class="built_in">float</span> cache[threadPerBlock];</span><br><span class="line">	</span><br><span class="line">	int tid = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">	int cacheId = threadIdx.x;	</span><br><span class="line">	<span class="built_in">float</span> tmp;	</span><br><span class="line">	<span class="keyword">while</span>(tid&lt;N)&#123;</span><br><span class="line">		tmp += a[tid]*b[tid];</span><br><span class="line">		tid+=blockDim.x*gridDim.x;	</span><br><span class="line">	&#125;</span><br><span class="line">	cache[cacheId] = tmp;</span><br><span class="line">	__syncthreads();</span><br><span class="line"></span><br><span class="line">	//reduction</span><br><span class="line">	int i = blockDim.x/2;</span><br><span class="line">	<span class="keyword">while</span>(i&gt;0)&#123;</span><br><span class="line">		<span class="keyword">if</span>(cacheId&lt;i)&#123;</span><br><span class="line">			cache[cacheId] += cache[cacheId+i];		</span><br><span class="line">		&#125;</span><br><span class="line">		__syncthreads();</span><br><span class="line">		i = i/2;	</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(cacheId == 0)&#123;</span><br><span class="line">		sum[blockIdx.x] = cache[0];	</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(void)&#123;</span><br><span class="line">	<span class="built_in">float</span> *a,*b,*partial_sum;</span><br><span class="line">	<span class="built_in">float</span> *dev_a,*dev_b,*dev_partial_sum;</span><br><span class="line"></span><br><span class="line">	a = (<span class="built_in">float</span>*)malloc(N*sizeof(<span class="built_in">float</span>));</span><br><span class="line">	b = (<span class="built_in">float</span>*)malloc(N*sizeof(<span class="built_in">float</span>));</span><br><span class="line">	partial_sum = (<span class="built_in">float</span>*)malloc(blockPerGrid*sizeof(<span class="built_in">float</span>));</span><br><span class="line">	</span><br><span class="line">	cudaMalloc((void**)&amp;dev_a,N*sizeof(<span class="built_in">float</span>));</span><br><span class="line">	cudaMalloc((void**)&amp;dev_b,N*sizeof(<span class="built_in">float</span>));</span><br><span class="line">	cudaMalloc((void**)&amp;dev_partial_sum,blockPerGrid*sizeof(<span class="built_in">float</span>));</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span>(int i=0;i&lt;N;i++)&#123;</span><br><span class="line">		a[i] = i;</span><br><span class="line">		b[i] = i*2;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	cudaMemcpy(dev_a,a,N*sizeof(<span class="built_in">float</span>),cudaMemcpyHostToDevice);</span><br><span class="line">	cudaMemcpy(dev_b,b,N*sizeof(<span class="built_in">float</span>),cudaMemcpyHostToDevice);</span><br><span class="line">	</span><br><span class="line">	dot&lt;&lt;&lt;blockPerGrid,threadPerBlock&gt;&gt;&gt;(dev_a,dev_b,dev_partial_sum);</span><br><span class="line"></span><br><span class="line">	cudaMemcpy(partial_sum,dev_partial_sum,blockPerGrid*sizeof(<span class="built_in">float</span>),cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">	<span class="built_in">float</span> ans = 0;</span><br><span class="line">	<span class="keyword">for</span>(int i=0;i&lt;blockPerGrid;i++)</span><br><span class="line">		ans += partial_sum[i];</span><br><span class="line"></span><br><span class="line">	<span class="comment">#define sum_squares(x) (x*(x+1)*(2*x+1)/6)	</span></span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"%.10g\n"</span>,(double)2*(N-1)*N*(2*N-1)/6);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"%.10g\n"</span>,ans);</span><br><span class="line">	</span><br><span class="line">	cudaFree(dev_a);</span><br><span class="line">	cudaFree(dev_b);</span><br><span class="line">	cudaFree(dev_partial_sum);</span><br><span class="line"></span><br><span class="line">	free(a);</span><br><span class="line">	free(b);</span><br><span class="line">	free(partial_sum);</span><br><span class="line"></span><br><span class="line">	<span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="常量内存"><a href="#常量内存" class="headerlink" title="常量内存"></a>常量内存</h2><p>用于保存核函数执行期间不会发生变化的数据。NVIDIA只提供了64KB的常量内存。与全局存储器不同，它拥有缓存，访问常量内存数据的时间仅为全局存储器的1/16。</p>
<p>适用情形：权重数组，系数矩阵，搜索偏移序列</p>
<p>使用方法：<br> 1）在定义时初始化常量内存，然后在kernel里面直接使用<br>    __constant__ int weight[10] = {0,1,2,3,4,5,6,7,8,9};</p>
<p> 2）定义一个constant数组，然后使用函数进行复制<br>    __constant__ int weight[10];<br>    int w[10] = {0,1,2,3,4,5,6,7,8,9};<br>    cudaMemcpyToSymbol(weight,w,sizeof(weight));</p>
<p>例子:为字符串“hdjik CUDA”每一位字符进行偏移，偏移值存储在常量内存中</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include&lt;stdio.h&gt;</span></span><br><span class="line"><span class="comment">#include&lt;cuda_runtime.h&gt;</span></span><br><span class="line"></span><br><span class="line">__constant__ char p_HelloCUDA[11];</span><br><span class="line">__constant__ int t_HelloCUDA[11] = &#123;0,1,2,3,4,5,6,7,8,9,10&#125;;</span><br><span class="line">__constant__ int num = 11;</span><br><span class="line"></span><br><span class="line">__global__ static void HelloCUDA(char* result)&#123;</span><br><span class="line">	int i = 0;</span><br><span class="line">	<span class="keyword">for</span>(i=0; i&lt;num; i++)</span><br><span class="line">		result[i] = p_HelloCUDA[i] + t_HelloCUDA[i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(int argc, char* argv[])&#123;</span><br><span class="line">	char helloCUDA[] = <span class="string">"Hdjik CUDA"</span>;</span><br><span class="line">	char *device_result;</span><br><span class="line">	char host_result[12] = &#123;0&#125;;</span><br><span class="line"></span><br><span class="line">	cudaMalloc((void**)&amp;device_result,11*sizeof(char));</span><br><span class="line">	cudaMemcpyToSymbol(p_HelloCUDA, helloCUDA,11*sizeof(char));</span><br><span class="line"></span><br><span class="line">	HelloCUDA&lt;&lt;&lt;1,1,0&gt;&gt;&gt;(device_result);</span><br><span class="line">	cudaMemcpy(&amp;host_result,device_result,11*sizeof(char),cudaMemcpyDeviceToHost);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"%s\n"</span>,host_result);</span><br><span class="line">	cudaFree(device_result);</span><br><span class="line">	<span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="纹理内存"><a href="#纹理内存" class="headerlink" title="纹理内存"></a>纹理内存</h2><p>一种只读存储器，专门为那些在内存访问模式中存在大量空间局部性的图形应用程序设计。在计算应用中，适合于邻近线程读取的内存位置非常接近的情况。（不需要内存对齐）</p>
<p><img src="/images/1.png" alt=""></p>
<p>声明: texture&lt;type,Dim,ReadMode&gt;texRef; (Dim默认为1,ReadMode默认为cudaReadModeElementType)</p>
<p>使用：<br>  1）将变量绑定到内存缓冲区（数据上传至设备缓存，核函数中可以直接访问）<br>     cudaBinkTexture(offset, texRef, devPre, desc, UINT_MAX);<br>     (后两个参数可省略)</p>
<p>  2）读取纹理内存中的数据方法<br>     text1Dfetch（）<br>     访问texRef数组的二个元素：tex1Dfetch（texRef, 1);</p>
<p>  3）取消绑定纹理内存，释放空间<br>     cudaUnbindTexture(texRef);</p>
<p>例子：    用字符串A给字符串B赋值</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include&lt;stdio.h&gt;</span></span><br><span class="line"><span class="comment">#include&lt;cuda_runtime.h&gt;</span></span><br><span class="line"></span><br><span class="line">const int len = 100;</span><br><span class="line"></span><br><span class="line">texture&lt;int&gt; texref;</span><br><span class="line"></span><br><span class="line">__global__ void blending_texture(int* dev_target,int size)&#123;</span><br><span class="line">	int tid = threadIdx.x + blockIdx.x*blockDim.x;</span><br><span class="line">	<span class="keyword">if</span>(tid&lt;size)&#123;</span><br><span class="line">		dev_target[tid] = tex1Dfetch(texref,tid);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>()&#123;</span><br><span class="line">	int *a,*b;</span><br><span class="line">	a = new int[len];</span><br><span class="line">	b = new int[len];</span><br><span class="line"></span><br><span class="line">	int *dev_source,*dev_target;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span>(int i=0;i&lt;len;i++)</span><br><span class="line">		a[i] = i;</span><br><span class="line"></span><br><span class="line">	cudaMalloc((void**)&amp;dev_source,len*sizeof(int));</span><br><span class="line">	cudaMalloc((void**)&amp;dev_target,len*sizeof(int));</span><br><span class="line">	cudaMemcpy(dev_source,a,len*sizeof(int),cudaMemcpyHostToDevice);</span><br><span class="line">	cudaBindTexture(NULL,texref,dev_source);	</span><br><span class="line"></span><br><span class="line">	blending_texture &lt;&lt;&lt;10,10&gt;&gt;&gt; (dev_target,100);</span><br><span class="line">	cudaMemcpy(b,dev_target,len*sizeof(int),cudaMemcpyDeviceToHost);</span><br><span class="line">	cudaUnbindTexture(texref);</span><br><span class="line">	cudaFree(dev_source);</span><br><span class="line">	cudaFree(dev_target);</span><br><span class="line">	<span class="keyword">for</span>(int i=0;i&lt;len;i++)</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"%d "</span>,a[i]);	</span><br><span class="line">	<span class="keyword">for</span>(int i=0;i&lt;len;i++)</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"%d "</span>,b[i]);</span><br><span class="line">	<span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/18/快速幂/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="DingHH">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="魔力弹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/18/快速幂/" itemprop="url">快速幂与矩阵快速幂</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-18T21:09:13+08:00">
                2018-09-18
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/09/18/快速幂/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/09/18/快速幂/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>计算（A^B）%mod，如果B的数据给的特别大，那么循环相乘时间复杂度O（n）就会崩。为了降低时间复杂度，使用快速幂进行求解。</p>
<h2 id="快速幂"><a href="#快速幂" class="headerlink" title="快速幂"></a>快速幂</h2><p>给出计算式（A^B）% mod，首先可以把B转换成二进制形式。<br>比如例子2^45 = 2^101101(2) = 2^100000(2) <em> 2^1000(2) </em> 2^100(2) * 2^1(2)，我们遍历B的二进制的每一位，判断其是否为1，并同时更新a表示该位上的1所代表的数值。如为1则将答案乘以a。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ll quick_pow(ll a, ll b, ll mod)&#123;</span><br><span class="line">    ll ans = 1;</span><br><span class="line">    <span class="keyword">while</span>(b)&#123;</span><br><span class="line">        <span class="keyword">if</span>(b&amp;1) ans=(ans*a)%mod;</span><br><span class="line">        a=(a*a)%mod;</span><br><span class="line">        b &gt;&gt;= 1;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">return</span> ans;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="矩阵快速幂"><a href="#矩阵快速幂" class="headerlink" title="矩阵快速幂"></a>矩阵快速幂</h2><p>将上述的方法稍加推广，可以发现，快速幂的方法还可以应用在很多运算上。<br>二元运算⊙满足a^(n+m) = a^n⊙a^m，则可以使用快速幂。</p>
<p>快速幂有个很常见的应用，就是矩阵快速幂，方法与上面一样，只不过要写一个矩阵的乘法。</p>
<p>我的矩阵快速幂模板</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#define ll long long</span></span><br><span class="line"><span class="comment">#define MOD 1000000007</span></span><br><span class="line">using namespace std;</span><br><span class="line">const int maxn = 100;</span><br><span class="line">struct mat&#123;</span><br><span class="line">    ll m[maxn][maxn];</span><br><span class="line">&#125;unit;</span><br><span class="line"></span><br><span class="line">mat mat_mul(mat a, mat b, int n)&#123;</span><br><span class="line">    mat matrix;</span><br><span class="line">    memset(matrix.m,0,sizeof(matrix.m));</span><br><span class="line">    <span class="keyword">for</span>(int i=0;i&lt;n;i++)</span><br><span class="line">    <span class="keyword">for</span>(int j=0;j&lt;n;j++)</span><br><span class="line">    <span class="keyword">for</span>(int k=0;k&lt;n;k++)&#123;</span><br><span class="line">        matrix.m[i][j]+=a.m[i][k]*b.m[k][j];</span><br><span class="line">        matrix.m[i][j]%=MOD;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">return</span> matrix;</span><br><span class="line">&#125;</span><br><span class="line">mat quick_pow(ll num, int n)&#123;</span><br><span class="line">    mat ans=unit,tmp=unit;</span><br><span class="line">    <span class="keyword">while</span>(num)&#123;</span><br><span class="line">        <span class="keyword">if</span>(num&amp;1)&#123;</span><br><span class="line">            ans = mat_mul(ans,tmp,n);</span><br><span class="line">        &#125;</span><br><span class="line">        tmp = mat_mul(tmp,tmp,n);</span><br><span class="line">        num &gt;&gt;= 1;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">return</span> ans;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><h3 id="Give-Candies（根据小费马定理降幂后快速幂）"><a href="#Give-Candies（根据小费马定理降幂后快速幂）" class="headerlink" title="Give Candies（根据小费马定理降幂后快速幂）"></a>Give Candies（根据小费马定理降幂后快速幂）</h3><p>题目链接:<a href="https://nanti.jisuanke.com/t/31716" target="_blank" rel="noopener">ACM-ICPC 2018 焦作赛区网络预赛G题</a><br>根据题目容易找到答案就为2^(n-1)，然而n的取值范围为100000次方，就算用字符串存再用快速幂也炸时间了。这里就刚好搬出小费马定理了：</p>
<p>(a^n)%p = a^(n%(p-1))%p</p>
<p>因此，只需要先求出n%(p-1)，再用这个数对a做快速幂就ok啦！</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#define ll long long</span></span><br><span class="line"><span class="comment">#define MOD 1000000007</span></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">char n[100050];</span><br><span class="line"></span><br><span class="line">//小费马定理:a^n%p = a^(n%(p-1))%p</span><br><span class="line"></span><br><span class="line">ll quick_pow(ll a, ll n)&#123;</span><br><span class="line">    ll ans = 1;</span><br><span class="line">    <span class="keyword">while</span>(n)&#123;</span><br><span class="line">        <span class="keyword">if</span>(n&amp;1) ans=(ans*a)%MOD;</span><br><span class="line">        a=(a*a)%MOD;</span><br><span class="line">        n &gt;&gt;= 1;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">return</span> ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    int t;</span><br><span class="line">    scanf(<span class="string">"%d"</span>,&amp;t);</span><br><span class="line">    <span class="keyword">while</span>(t--)&#123;</span><br><span class="line">        scanf(<span class="string">"%s"</span>,n);</span><br><span class="line">        int l = strlen(n);</span><br><span class="line">        ll sum = 0;</span><br><span class="line">		/求出n%(p-1）</span><br><span class="line">        <span class="keyword">for</span>(int i=0;i&lt;l;i++)&#123;</span><br><span class="line">            sum *= 10;</span><br><span class="line">            sum += n[i] - <span class="string">'0'</span>;</span><br><span class="line">            sum %= MOD-1;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%lld\n"</span>,quick_pow(2,sum-1));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Poor-God-Water-递推公式推导矩阵"><a href="#Poor-God-Water-递推公式推导矩阵" class="headerlink" title="Poor God Water (递推公式推导矩阵)"></a>Poor God Water (递推公式推导矩阵)</h3><p>题目链接:<a href="https://nanti.jisuanke.com/t/31721" target="_blank" rel="noopener">ACM-ICPC 2018 焦作赛区网络预赛L题</a></p>
<p>是看了<a href="http://www.cnblogs.com/shinianhuanniyijuhaojiubujian/p/9651533.html" target="_blank" rel="noopener">这个</a>博客才知道怎么做的，用矩阵快速幂真是妙啊0_0</p>
<p>然后是我的代码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;vector&gt;</span></span><br><span class="line"><span class="comment">#include &lt;string&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;ctime&gt;</span></span><br><span class="line"><span class="comment">#define ll long long</span></span><br><span class="line"><span class="comment">#define MOD 1000000007</span></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct mat&#123;</span><br><span class="line">    ll m[9][9];</span><br><span class="line">&#125;unit;</span><br><span class="line"></span><br><span class="line">void <span class="function"><span class="title">init</span></span>()&#123;</span><br><span class="line">    memset(unit.m,0,sizeof(unit.m));</span><br><span class="line">    unit.m[5][0] = unit.m[7][0] = 1;</span><br><span class="line">    unit.m[3][1] = unit.m[5][1] = unit.m[7][1] = 1;</span><br><span class="line">    unit.m[4][2] = unit.m[6][2] = 1;</span><br><span class="line">    unit.m[0][3] = unit.m[6][3] = 1;</span><br><span class="line">    unit.m[1][4] = unit.m[8][4] = 1;</span><br><span class="line">    unit.m[1][5] = unit.m[2][5] = unit.m[8][5] = 1;</span><br><span class="line">    unit.m[0][6] = unit.m[4][6] = 1;</span><br><span class="line">    unit.m[3][7] = unit.m[5][7] = 1;</span><br><span class="line">    unit.m[1][8] = unit.m[2][8] = 1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">mat mat_mul(mat a, mat b)&#123;</span><br><span class="line">    mat matrix;</span><br><span class="line">    memset(matrix.m,0,sizeof(matrix.m));</span><br><span class="line">    <span class="keyword">for</span>(int i=0;i&lt;9;i++)</span><br><span class="line">    <span class="keyword">for</span>(int j=0;j&lt;9;j++)</span><br><span class="line">    <span class="keyword">for</span>(int k=0;k&lt;9;k++)&#123;</span><br><span class="line">        matrix.m[i][j]+=a.m[i][k]*b.m[k][j];</span><br><span class="line">        matrix.m[i][j]%=MOD;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">return</span> matrix;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void print_mat(mat a)&#123;</span><br><span class="line">    <span class="keyword">for</span>(int i=0;i&lt;9;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(int j=0;j&lt;9;j++)&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%lld "</span>,a.m[i][j]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">mat quick_pow(ll num)&#123;</span><br><span class="line">    mat ans=unit,tmp=unit;</span><br><span class="line">//    print_mat(ans);</span><br><span class="line">//    print_mat(tmp);</span><br><span class="line">    <span class="keyword">while</span>(num)&#123;</span><br><span class="line">        <span class="keyword">if</span>(num&amp;1)&#123;</span><br><span class="line">            ans = mat_mul(ans,tmp);</span><br><span class="line">//            print_mat(ans);</span><br><span class="line">        &#125;</span><br><span class="line">        tmp = mat_mul(tmp,tmp);</span><br><span class="line">        num &gt;&gt;= 1;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">return</span> ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>()&#123;</span><br><span class="line">    int n;</span><br><span class="line">    scanf(<span class="string">"%d"</span>,&amp;n);</span><br><span class="line">    ll num;</span><br><span class="line">    init();</span><br><span class="line">    <span class="keyword">while</span>(n--)&#123;</span><br><span class="line">        scanf(<span class="string">"%lld"</span>,&amp;num);</span><br><span class="line">        <span class="keyword">if</span>(num==1)&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"3\n"</span>);</span><br><span class="line">            <span class="built_in">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(num==2)&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"9\n"</span>);</span><br><span class="line">            <span class="built_in">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        mat res = quick_pow(num-3);</span><br><span class="line">        ll ans = 0;</span><br><span class="line">        <span class="keyword">for</span>(int i=0;i&lt;9;i++)</span><br><span class="line">            <span class="keyword">for</span>(int j=0;j&lt;9;j++)&#123;</span><br><span class="line">                ans += res.m[i][j];</span><br><span class="line">                ans %= MOD;</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%lld\n"</span>,ans);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/14/faster-rcnn代码阅读（数据的集读入imdb，riodb）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="DingHH">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="魔力弹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/14/faster-rcnn代码阅读（数据的集读入imdb，riodb）/" itemprop="url">faster rcnn 代码阅读笔记 ——数据集的读入（imdb，roidb）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-14T22:23:31+08:00">
                2018-09-14
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/09/14/faster-rcnn代码阅读（数据的集读入imdb，riodb）/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/09/14/faster-rcnn代码阅读（数据的集读入imdb，riodb）/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>数据集在faster rcnn的代码中是以通过一个类imdb组织起来的，这个类可以被成为图像数据库，包含一个数据集的基本信息，如名称，图片数，目标种类数。roidb则作为imdb的一个成员，存储了每一张具体图片上的感兴趣区域信息（regions of interests）。</p>
<p>从train.py文件开始分析，imdb和roidb是如何一步步生成的。<br>在类Train的构造函数中，将数据集名字作为参数imdb_names传入到同一文件的combined_roidb函数中去。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.imdb, self.roidb = combined_roidb(<span class="string">"voc_2007_trainval"</span>)</span><br></pre></td></tr></table></figure>
<p>在这个combined_roidb函数中，将参数imdb_names按照分隔符“+”进行分割，以处理多个数据集的情况，当然在这里只传入了一个数据集的名字。并将分割后的imdb名称分别作为参数调用了嵌套在其自身内的get_roidb函数得到roidb。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">roidbs = [get_roidb(s) <span class="keyword">for</span> s <span class="keyword">in</span> imdb_names.split(<span class="string">'+'</span>)]</span><br></pre></td></tr></table></figure>
<h3 id="生成imdb"><a href="#生成imdb" class="headerlink" title="生成imdb"></a>生成imdb</h3><p>具体在get_roidb函数内，首先调用get_imdb，得到imdb，在get_imdb函数中，获取得到pascal_voc(split,year)。在这里，也就相当于调用了pascal_voc(trainval，2007)，得到了一个pascal_voc格式的数据集。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> year <span class="keyword">in</span> [<span class="string">'2007'</span>, <span class="string">'2012'</span>]:</span><br><span class="line">  <span class="keyword">for</span> split <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'val'</span>, <span class="string">'trainval'</span>, <span class="string">'test'</span>]:</span><br><span class="line">    name = <span class="string">'voc_&#123;&#125;_&#123;&#125;'</span>.format(year, split)</span><br><span class="line">    __sets[name] = (lambda split=split, year=year: pascal_voc(split, year))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> year <span class="keyword">in</span> [<span class="string">'2014'</span>]:</span><br><span class="line">  <span class="keyword">for</span> split <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'val'</span>, <span class="string">'minival'</span>, <span class="string">'valminusminival'</span>, <span class="string">'trainval'</span>]:</span><br><span class="line">    name = <span class="string">'coco_&#123;&#125;_&#123;&#125;'</span>.format(year, split)</span><br><span class="line">    __sets[name] = (lambda split=split, year=year: coco(split, year))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> year <span class="keyword">in</span> [<span class="string">'2015'</span>]:</span><br><span class="line">  <span class="keyword">for</span> split <span class="keyword">in</span> [<span class="string">'test'</span>, <span class="string">'test-dev'</span>]:</span><br><span class="line">    name = <span class="string">'coco_&#123;&#125;_&#123;&#125;'</span>.format(year, split)</span><br><span class="line">    __sets[name] = (lambda split=split, year=year: coco(split, year))</span><br><span class="line"></span><br><span class="line">def get_imdb(name):</span><br><span class="line">  <span class="keyword">if</span> name not <span class="keyword">in</span> __sets:</span><br><span class="line">    raise KeyError(<span class="string">'Unknown dataset: &#123;&#125;'</span>.format(name))</span><br><span class="line">  <span class="built_in">return</span> __sets[name]()</span><br></pre></td></tr></table></figure>
<p>pascal_voc继承自imdb，增加了更多的关于数据集的属性信息，在pascal_voc的初始化函数中，定义了诸如数据集的名字，存储路径，带识别图像类别以及其对应索引号，图像后缀名之类的属性，加载了数据集中所含图片的索引，以及该数据集的roidb。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">def __init__(self, image_set, year, devkit_path=None):</span><br><span class="line">        imdb.__init__(self, <span class="string">'voc_'</span> + year + <span class="string">'_'</span> + image_set)</span><br><span class="line">        self._year = year</span><br><span class="line">        self._image_set = image_set</span><br><span class="line">        self._devkit_path = self._get_default_path() <span class="keyword">if</span> devkit_path is None \</span><br><span class="line">            <span class="keyword">else</span> devkit_path</span><br><span class="line">        self._data_path = os.path.join(self._devkit_path, <span class="string">'VOC'</span> + self._year) <span class="comment">#设置数据集路径</span></span><br><span class="line">        self._classes = (<span class="string">'__background__'</span>,  <span class="comment"># always index 0</span></span><br><span class="line">                        <span class="string">'336'</span>,u<span class="string">'cilang'</span>,u<span class="string">'dahongshi'</span>,u<span class="string">'guanguanshi'</span>,u<span class="string">'heishi'</span>,u<span class="string">'huaitaishi'</span>,u<span class="string">'huoguan'</span>,u<span class="string">'jinzaoshi'</span>,u<span class="string">'mopanshi'</span>,u<span class="string">'zhoushanchangshi'</span>)<span class="comment">#'jueyuanzi')#'purewater', 'ckiwi', 'cherrycola', 'walnut','clemon','cola500','coconut','sprit','clemon','zerocola')  #设置类别</span></span><br><span class="line">        self._class_to_ind = dict(list(zip(self.classes, list(range(self.num_classes))))) <span class="comment">#设置类别索引</span></span><br><span class="line">        self._image_ext = <span class="string">'.jpg'</span></span><br><span class="line">        self._image_index = self._load_image_set_index() <span class="comment">#加载图片索引</span></span><br><span class="line">        <span class="comment"># Default to roidb handler</span></span><br><span class="line">        self._roidb_handler = self.gt_roidb</span><br><span class="line">        self._salt = str(uuid.uuid4())</span><br><span class="line">        self._comp_id = <span class="string">'comp4'</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># PASCAL specific config options</span></span><br><span class="line">        self.config = &#123;<span class="string">'cleanup'</span>: True,</span><br><span class="line">                       <span class="string">'use_salt'</span>: True,</span><br><span class="line">                       <span class="string">'use_diff'</span>: False,</span><br><span class="line">                       <span class="string">'matlab_eval'</span>: False,</span><br><span class="line">                       <span class="string">'rpn_file'</span>: None&#125;</span><br><span class="line"></span><br><span class="line">        assert os.path.exists(self._devkit_path), \</span><br><span class="line">            <span class="string">'VOCdevkit path does not exist: &#123;&#125;'</span>.format(self._devkit_path)</span><br><span class="line">        assert os.path.exists(self._data_path), \</span><br><span class="line">            <span class="string">'Path does not exist: &#123;&#125;'</span>.format(self._data_path)</span><br></pre></td></tr></table></figure>
<p>值得注意的地方有roidb_handler，这个在生成roidb时起到作用。还有就是加载图片索引部分。在这里，使用了一个load_image_set_index函数，打开数据集中Main文件内的txt文件，这个文件中存放着图片的名称，函数一行一行将图片的名称作为索引读到image_index里面。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def _load_image_set_index(self):</span><br><span class="line">        <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        Load the indexes listed in this dataset's image set file.</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line"></span><br><span class="line">        image_set_file = os.path.join(self._data_path, <span class="string">'ImageSets'</span>, <span class="string">'Main'</span>,</span><br><span class="line">                                      self._image_set + <span class="string">'.txt'</span>)</span><br><span class="line"></span><br><span class="line">        assert os.path.exists(image_set_file), \</span><br><span class="line">            <span class="string">'Path does not exist: &#123;&#125;'</span>.format(image_set_file)</span><br><span class="line">        with open(image_set_file) as f:</span><br><span class="line">            image_index = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> f.readlines()]</span><br><span class="line">        <span class="built_in">return</span> image_index</span><br></pre></td></tr></table></figure>
<p>到这里为止，imdb的内容就已经加载好了。</p>
<h3 id="roidb的生成"><a href="#roidb的生成" class="headerlink" title="roidb的生成"></a>roidb的生成</h3><p>接下来combined_roidb函数接着设置了一个proposal_method，这里设为了“gt”（这是为了之后生成roidb做的一个设置）。以及调用了 get_training_roidb。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def get_training_roidb(imdb):</span><br><span class="line">    <span class="string">""</span><span class="string">"Returns a roidb (Region of Interest database) for use in training."</span><span class="string">""</span></span><br><span class="line">    <span class="keyword">if</span> True:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">'Appending horizontally-flipped training examples...'</span>)</span><br><span class="line">        imdb.append_flipped_images() <span class="comment">#数据扩充，对图像进行翻转</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">'done'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'Preparing training data...'</span>)</span><br><span class="line">    rdl_roidb.prepare_roidb(imdb) <span class="comment">#准备roidb，将图片信息都读入到roidb数组内</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'done'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> imdb.roidb</span><br></pre></td></tr></table></figure>
<p>要说明的是，roidb为单张图片的信息，包括对象位置坐标信息等等，在程序里，具体用roidb[]字典存放数据集里所有图片的信息。即一张图有一个roidb，每个roidb是一个字典。</p>
<p>在append_flipped_images中，调用了pascal_voc中的gt_roidb（参照前面proposal_method设定为gt），转而调用了同一个文件中的_load_pascal_annotation，该函数根据图片的索引，到Annotations这个文件夹下去找相应的xml标注数据，然后加载所有的bounding box对象，xml的解析到此结束。prepare_roidb则是对roidb中的几个类成员的赋值。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">def gt_roidb(self):</span><br><span class="line">       <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">       Return the database of ground-truth regions of interest.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       This function loads/saves from/to a cache file to speed up future calls.</span></span><br><span class="line"><span class="string">       "</span><span class="string">""</span></span><br><span class="line">       cache_file = os.path.join(self.cache_path, self.name + <span class="string">'_gt_roidb.pkl'</span>)</span><br><span class="line">       <span class="keyword">if</span> os.path.exists(cache_file):</span><br><span class="line">           with open(cache_file, <span class="string">'rb'</span>) as fid:</span><br><span class="line">               try:</span><br><span class="line">                   roidb = pickle.load(fid)</span><br><span class="line">               except:</span><br><span class="line">                   roidb = pickle.load(fid, encoding=<span class="string">'bytes'</span>)</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">'&#123;&#125; gt roidb loaded from &#123;&#125;'</span>.format(self.name, cache_file))</span><br><span class="line">           <span class="built_in">return</span> roidb</span><br><span class="line"></span><br><span class="line">       gt_roidb = [self._load_pascal_annotation(index)</span><br><span class="line">                   <span class="keyword">for</span> index <span class="keyword">in</span> self.image_index]</span><br><span class="line">       with open(cache_file, <span class="string">'wb'</span>) as fid:</span><br><span class="line">           pickle.dump(gt_roidb, fid, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">       <span class="built_in">print</span>(<span class="string">'wrote gt roidb to &#123;&#125;'</span>.format(cache_file))</span><br><span class="line"></span><br><span class="line">       <span class="built_in">return</span> gt_roidb</span><br></pre></td></tr></table></figure>
<p>此时，roidb和imdb都已经加载得到，回到combined_roidb函数中，根据需要处理的数据集个数对roidb进行了一些相关处理，因为这里我们只用到一个数据集，所以直接返回了roidb和imdb。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">DingHH</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">DingHH</span>

  
</div>


  <div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>
  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: '7aGO4ceaSyFmqARGKgkEqkRE-gzGzoHsz',
        appKey: 'SMEf1qP35BUjnUV2X7Vdg8o2',
        placeholder: 'Just go go',
        avatar:'/images/avatar.jpg',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  

  

  
  

  

  

  

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","bottom":-30,"width":100,"height":200},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
<script type="text/javascript" src="/js/src/love.js"></script>
